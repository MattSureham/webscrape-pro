# WebScrape Pro ğŸ•¸ï¸

A comprehensive, production-ready web scraping toolkit with multiple engines, advanced features, and extensible architecture.

## Features

- **Multiple Scraping Engines**: Requests + BeautifulSoup, Selenium, Playwright, aiohttp (async)
- **Advanced Features**: Auto-retry, rate limiting, proxy rotation, caching, session management
- **Data Exporters**: JSON, CSV, Excel, SQLite, Parquet, MongoDB
- **Utilities**: URL parsing, form handling, pagination helpers, data validators
- **CLI Interface**: Command-line tool for quick scraping tasks
- **Docker Support**: Ready-to-use containerized environment
- **Extensible**: Plugin architecture for custom scrapers

## Quick Start

```bash
# Install
pip install -r requirements.txt

# Basic usage
python -m webscrape_pro https://example.com --output data.json

# Using the library
from webscrape_pro import SmartScraper

scraper = SmartScraper()
data = scraper.scrape('https://example.com')
```

## Repository Structure

```
webscrape-pro/
â”œâ”€â”€ webscrape_pro/          # Main package
â”‚   â”œâ”€â”€ core/               # Core scraping engines
â”‚   â”œâ”€â”€ utils/              # Utility functions
â”‚   â”œâ”€â”€ exporters/          # Data export modules
â”‚   â”œâ”€â”€ middleware/         # Middleware (caching, retries)
â”‚   â””â”€â”€ cli.py              # Command line interface
â”œâ”€â”€ examples/               # Usage examples
â”œâ”€â”€ tests/                  # Test suite
â”œâ”€â”€ docker/                 # Docker configuration
â””â”€â”€ docs/                   # Documentation
```

## License

MIT License
